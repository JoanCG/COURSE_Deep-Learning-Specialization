---
title: Introduction to Deep Learning
---

**Forward propagation**: process input data and obtain output variable. Measure the yield of the output, for example, using a cost function.

**Backward propagation**: derivate output data into new values for parameters (some of the input variables) that optimize the output (i.e., minimize the cost function)

Vectorization is used to speed up calculations, allowing to scale code without a high computational cost. It avoids "for loops" by using matrix multiplication. 

This computations can be parallelized through the SIMD (single instruction, multiple data) calculations. Both CPUs and GPUs are suited for this kind of calculations, but GPUs outperform CPUs. 




